%cd shap-e

! pip install -e 

import torch

from shap_e.diffusion.sample import sample_latents
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.models.download import load_model, load_config
from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

xm = load_model('transmitter', device=device)
model = load_model('text300M', device=device)
diffusion = diffusion_from_config(load_config('diffusion'))

!pip install googletrans==3.1.0a0

!pip install translate

import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/path/to/your/credentials.json"  # Set your API key path

from googletrans import Translator

# 1. Any Language Input
any_language_prompt = "శివుని ఆలయం" # Example: Sanskrit

# 2. Translate to English
translator = Translator()
english_prompt = translator.translate(any_language_prompt, dest='en').text
print("Translated Prompt:", english_prompt)

# 3. Use the translated English prompt in your sampling
from shap_e.diffusion.sample import sample_latents
batch_size = 4
guidance_scale = 30.0
prompt = english_prompt  # Using the translated prompt

latents = sample_latents(
    batch_size=batch_size,
    model=model,
    diffusion=diffusion,
    guidance_scale=guidance_scale,
    model_kwargs=dict(texts=[prompt] * batch_size),
    progress=True,
    clip_denoised=True,
    use_fp16=True,
    use_karras=True,
    karras_steps=128,
    sigma_min=1e-3,
    sigma_max=160,
    s_churn=0,
)

render_mode = 'nerf'  # Use NeRF rendering for faster results
# render_mode = 'stf' # Use SDF rendering for higher quality but potentially longer render times

size = 256  # Adjust size for faster results (smaller values are faster)

cameras = create_pan_cameras(size, device)
for i, latent in enumerate(latents):
    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)
    display(gif_widget(images))

from shap_e.util.notebooks import decode_latent_mesh

for i, latent in enumerate(latents):
    t = decode_latent_mesh(xm, latent).tri_mesh()
    with open(f'example_mesh_{i}.ply', 'wb') as f:
        t.write_ply(f)
    with open(f'example_mesh_{i}.obj', 'w') as f:
        t.write_obj(f)
